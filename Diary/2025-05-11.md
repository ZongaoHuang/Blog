# Daily Study
## Daily Plan
#todo
- [x] 写博客
- [ ] 
## 大模型相关问题
#暑期实习 

### 研判中出现误判或者错判怎么验证和处理
验证：
1. 最直接和可靠的方式是人工复合，根据专业知识进行二次研判。
2. 对比基准，在训练大模型的时候会准备测试训练集进行测试和验证

处理：
1. 系统采用了多维度研判的方式，包括三个方面，大模型语义研判，信息熵研判和自定义规则研判。最终研判结果是由三种研判方式的分值总和决定。其中自定义规则是可以人工干预的，能够根据已经发生的误判或者错判来修改和更新，从而提升准确率
2. 研判部分和降噪聚合部分也有反馈关系，可以将这些错判和误判的研判信息和结果，反馈到自定义白名单中和自定义告警规则中，形成反馈闭环。
3. 使用RAG增强
### 大模型的回复不按照设置的指令回复
主要原因：
1. Prompt设计问题：指令模糊不明确
2. 模型限制：模型对特定的指令理解不足，以及模型固有的创造性或幻觉等
3. API调用或者后处理问题：API参数不对，输出解析出现错误，解码的temperature设置过高
4. 微调引入的问题：微调数据集质量不高，微调过拟合

解决：
1. 优化Prompt：强调关键指令，明确输出格式，使用结构化输出
2. 调整解码参数，找到合适的top-k/p 
3. 推理过程或系统级架构优化

### 为什么用Lora不用RAG

参考链接：[知识图谱与大模型：微调 Vs. RAG - 知乎](https://zhuanlan.zhihu.com/p/688379522)

1.针对目标：
- 微调是用于扩展和更新模型内部知识或针对特定任务，适用于定制化内部行为，具体来说就是该系统就是针对告警日志进行智能研判。
- RAG则是一种检索增强技术，利用向量数据库充当大模型访问外部信息的接口，使用类似于Langchain的流程和插件，来获取最新的数据。
2.针对安全性：
- Lora训练的数据无需离开本地环境，仅调整模型参数即可完成训练。
- 外部知识库可能包含敏感信息，检索过程存在泄露风险（如医疗记录、法律文件）
3.针对资源与复杂度：
- 微调可以大幅度降低训练参数，适合企业级应用，主要是设置微调参数做实验
- RAG需要维护向量数据库，不断构建和更新索引
### 常见的告警信息


| 攻击类型               | 源告警数量  | 聚合告警数量 | 聚合率   |
| ------------------ | ------ | ------ | ----- |
| 发现使用远程连接工具向日葵      | 129370 | 1695   | 98.69 |
| 发现Web空口令登录行为       | 70869  | 383    | 99.46 |
| Java代码执行攻击(机器学习)   | 48995  | 1053   | 97.85 |
| SMB账号暴力猜解          | 8309   | 376    | 95.48 |
| 发现远程连接工具ToDesk通信流量 | 7970   | 410    | 94.86 |
| 发现域用户口令爆破行为        | 6903   | 387    | 94.39 |
| IMAP明文密码           | 6497   | 97     | 98.51 |
| 疑似SSH账号暴力猜解        | 4465   | 34     | 99.24 |
| SQL注入攻击            | 2877   | 898    | 68.78 |

### 具体的评分方法和阈值
见仓库ReadME