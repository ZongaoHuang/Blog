# Daily Study
## Daily Plan
#todo
- [x] 写博客
- [ ] 
## AI + 前后端分离应用的渗透测试
未完待续

基础方案总结：[前后端分离应用的渗透测试方案](../Misc/Security/Web安全/前后端分离应用的渗透测试方案.md)

大模型初步的思路如下：

### **1. 优化阶段一：AI增强的侦察与攻击面测绘**

在信息侦察阶段，LLM能够极大地提升发现隐藏API端点和参数的效率与深度。

- **智能化的静态代码分析**：传统工具如LinkFinder使用正则表达式在JavaScript文件中搜索API端点 。LLM则更进一步，它们不仅是匹配模式，还能**理解代码的上下文和逻辑** 。  
    
    - **应用**：您可以向LLM提供一个压缩或混淆的前端JavaScript文件，并提出这样的提示：“分析此JavaScript代码，识别并列出所有与后端通信的API端点、它们使用的HTTP方法以及相关的参数。” LLM能够解析代码逻辑，找出通过`fetch`或`XMLHttpRequest`发起的动态API调用，这是传统静态分析工具难以做到的 。  
        
    - **优势**：这种方法对于发现那些在常规UI交互中不会触发的、为未来功能预留的或由复杂逻辑动态构建的API端点尤其有效。
- **自动化API文档解析与摘要**：当获得Swagger或OpenAPI等API文档时，LLM可以快速解析这些通常很冗长的文件 。  
    
    - **应用**：您可以让LLM“阅读”整个API规范，并生成一份摘要，突出显示那些处理敏感数据（如个人身份信息PII）、执行关键业务操作（如支付、授权）或参数复杂的端点，从而帮助测试人员迅速确定高风险的测试目标。

### **2. 优化阶段二：更智能的漏洞分析与利用**

在漏洞分析阶段，LLM的优势在于其生成上下文感知测试用例和识别复杂逻辑漏洞的能力。

- **智能模糊测试 (Smart Fuzzing)**：传统的模糊测试（Fuzzing）通常是向API发送大量随机或半随机的数据。而LLM可以生成更具智能和上下文的测试负载 。  
    
    - **应用**：针对一个API端点，您可以指示LLM：“为此API端点生成一系列模糊测试负载，专门用于测试SQL注入和跨站脚本（XSS）漏洞，请确保负载在语法上是有效的，以绕过基础的输入过滤器。” LLM可以生成更巧妙、更可能绕过防御的攻击向量 。  
        
    - **优势**：这种“智能模糊测试”能更有效地发现深层次的漏洞，因为它不仅仅是随机碰撞，而是模拟攻击者的思维来构造payload 。  
        
- **业务逻辑漏洞发现**：业务逻辑漏洞是传统自动化扫描器最难发现的领域，因为它们需要理解应用的预期工作流程 。LLM在这方面表现出色。  
    
    - **应用**：测试人员可以向LLM描述一个正常的业务流程（例如，“一个正常的购物流程是：1. 添加商品到购物车；2. 应用优惠券；3. 支付”），然后要求LLM设计出可能绕过或滥用该流程的API调用序列 。例如：“请设计一套API请求序列，尝试在不满足优惠券使用条件的情况下完成支付。”  
        
    - **优势**：LLM能够基于对业务逻辑的理解，创造性地发现那些因开发者错误假设用户行为而产生的漏洞 。  
        
- **自动化测试脚本生成**：对于CI/CD流水线中的自动化安全测试，LLM可以显著降低编写测试用例的门槛 。  
    
    - **应用**：您可以直接用自然语言向LLM下达指令：“为Postman创建一个测试集合，针对`/api/users`端点编写测试用例，验证当使用有效的JWT令牌时返回200状态码，当没有令牌时返回401状态码，并检查响应体是否符合指定的JSON Schema。” LLM可以直接生成可执行的Postman测试脚本