# Daily Study
## Daily Plan
#todo
- [x] 写博客
- [ ] 
## 场景题
### 对AI的理解
在我看来，AI 的核心在于**模仿、延伸和放大**人类的智能。它不仅仅是自动化，更是关于学习、推理、感知、决策和创造。从弱人工智能（ANI）专注于特定任务，到我们仍在探索的通用人工智能（AGI），AI 的发展正在深刻改变各个行业。

关于我接触的两个领域，安全和大模型应用领域，我对AI的理解如下。

对于安全领域的防御方：
- AI能够提升智能检测与响应的能力，包括异常检测，恶意软件分析，入侵检测，管理与响应。
- AI能够提升身份认证与访问控制，包括生物识别，行为分析来做一些验证
- AI能够对漏洞进行管理和风险评估
对于安全领域的攻击方：
- AI能够做一些自动化攻击工具，自动化的发现和利用漏洞，然后进行大规模自动化的攻击
- AI能够利用深度学习进行一些身份的伪造，然后进行敲诈
- 攻击者可以做一些对抗攻击，欺骗AI模型，从而导致其做出误判和分类
- 攻击者还可以通过污染训练数据对AI做投毒攻击

对于大模型应用领域：
- 内容生成与辅助创作： 撰写邮件、报告、代码、营销文案、剧本等。
- 智能问答与对话系统： 作为客服、个人助手、信息检索工具。
- 代码生成与辅助开发： 帮助开发者编写、调试、解释和转换代码。
- 数据分析与洞察： 从大量文本数据中提取摘要、趋势、情感。
- 教育与培训： 个性化辅导、生成学习材料。
- 机器翻译与自然语言理解。

总结来说，我对大模型的理解，它在专业领域相当于是一把双刃剑，不仅要关注于它带来的便利，也要防范它带来的危害。关键在于：
- 持续的攻防演练：防御方需要不断利用AI提升能力，同时研究AI可能带来的新威胁。
- 关注LLM自身的安全：加强对提示注入、数据泄露等LLM特有漏洞的研究和防护。发展更安全的LLM架构和训练方法。
- 人机协同：AI目前还不能完全取代人类安全专家。最佳实践是人机协同，AI作为强大的助手，辅助人类专家进行决策和操作。

### 对一个好的大模型应用的理解

1. **清晰的价值主张与精准的问题解决 (Clear Value Proposition & Problem Solving):**
    - **解决真实痛点，而非“为了用LLM而用LLM”**: 应用的核心应该是解决用户或业务面临的实际问题，LLM只是实现解决方案的工具。如果传统方法能更简单、经济、有效地解决问题，就不应强行使用LLM。
    - **发挥LLM的独特优势**: 好的应用会巧妙利用LLM在自然语言理解、生成、摘要、翻译、代码生成、复杂推理（在一定程度上）等方面的长处。例如，自动化繁琐的文本处理、提供个性化内容、赋能更自然的交互等。
    - **价值可衡量**: 应用的价值应该是可以被感知的，无论是提升效率、降低成本、创造新体验，还是赋能新的业务模式。
2. **卓越的用户体验 (Excellent User Experience - UX):**
    - **自然流畅的交互**: 用户与应用的交互应该尽可能直观、自然。如果涉及对话，那么对话管理、上下文理解、多轮交互能力至关重要。
    - **有效的引导与预期管理**: LLM并非万能，应用需要清晰地告知用户其能力边界，并通过良好的设计（如有效的提示工程、示例、模板）引导用户获得最佳输出，管理用户的期望值。
    - **迭代与修正能力**: 用户应该能够方便地对LLM的输出进行反馈、修正或要求重新生成，形成一个有效的“人机协作”闭环。
    - **上下文感知与个性化**: 好的应用能够记住历史交互信息、用户偏好，提供更具个性化和连贯性的体验。
    - **适当的反馈与透明度**: 在适当的时候，应用可以解释LLM是如何得出结论的（例如，通过引用来源——尤其在使用RAG时），或给出置信度，增加用户的信任感。
3. **可靠性与可信赖性 (Reliability & Trustworthiness):**
    - **准确性与事实性控制**: 这是LLM应用面临的最大挑战之一。好的应用会采用多种策略来减少“幻觉”（hallucinations）和事实性错误，例如：
        - **检索增强生成 (Retrieval Augmented Generation - RAG)**: 将LLM与可靠的外部知识库或私有数据库结合，让LLM基于检索到的信息进行回答和生成，而不是仅依赖其内部训练数据。
        - **Grounding (接地)**: 将LLM的输出与特定事实、数据源进行锚定。
        - **严格的后处理和验证**: 对LLM的输出进行事实核查或规则校验。
    - **一致性与可预测性**: 在相似的输入下，应用应该能提供相对一致和可预测的输出（除非其设计目标是创造性输出）。通过精细的系统提示（System Prompt）和参数调整来实现。
    - **鲁棒性与错误处理**: 应用需要能够优雅地处理不明确的输入、超出LLM能力范围的请求，并给出清晰的错误提示或引导。
4. **深度技术整合与巧妙的系统设计 (Deep Technical Integration & Smart System Design):**
    - **不仅仅是“API套壳”**: 优秀的应用通常会将LLM作为核心组件，但会围绕它构建复杂的系统，包括数据预处理、精巧的提示工程、与其他业务逻辑和数据系统的集成、以及输出的后处理等。
    - **“人机回圈” (Human-in-the-Loop)**: 对于关键决策或高风险任务，应设计人工审核和干预的环节，确保安全和质量。
    - **模型选择与优化**: 根据具体任务选择最合适的LLM（考虑能力、成本、速度等因素），甚至可能需要对基础模型进行微调（Fine-tuning）以适应特定领域或任务。
    - **可观测性与持续监控**: 建立完善的日志、监控和告警机制，追踪LLM的性能、输出质量、用户反馈、token消耗等，以便持续优化。
5. **负责任的AI与伦理考量 (Responsible AI & Ethical Considerations):**
    - **偏见缓解**: 认识到LLM可能存在的偏见，并采取措施（如数据增强、提示调整、输出过滤）来减轻其负面影响。
    - **数据隐私与安全**: 严格保护用户输入数据的隐私，尤其是在处理个人身份信息（PII）或其他敏感数据时。确保数据在传输、存储和处理过程中的安全。
    - **透明度与可解释性**: 尽可能让用户理解应用是如何工作的，以及为什么会产生特定的输出（尽管LLM的完全可解释性仍是难题）。
    - **防止滥用与有害内容生成**: 设置有效的护栏（guardrails）和内容过滤器，防止应用被用于生成仇恨言论、虚假信息、恶意代码等有害内容。
6. **高效性与可持续性 (Efficiency & Sustainability):**
    - **成本效益**: LLM的调用是有成本的（token消耗）。好的应用会优化提示长度、选择合适的模型、采用缓存等策略，以实现成本效益。
    - **性能与延迟**: 保证应用在可接受的时间内响应用户请求。对于实时性要求高的场景，需要特别关注LLM的推理速度和整体系统的延迟。
    - **可扩展性**: 应用架构需要能够支持用户量和数据量的增长。
总结来说，一个好的基于LLM的应用，是**以用户为中心，以解决实际问题为导向，巧妙利用LLM的优势，同时有效规避其固有缺陷，并通过精心的系统设计、用户体验打磨以及负责任的开发态度，最终为用户带来真实、可靠、高效价值的综合体现。** 它往往不是一个孤立的LLM，而是一个精心编排的、包含LLM在内的复杂系统。
### AI对后端的影响

AI正从根本上重塑后端开发，其核心影响体现在以下几个方面：

1. **开发效率与自动化飞跃**：
    
    - AI驱动代码生成（如API、业务逻辑、测试用例）、文档撰写及代码审查，大幅缩短开发周期。
    - 辅助Bug定位与修复建议，提升代码质量与维护效率。
2. **系统架构与运维智能化**：
    
    - 推动API网关、服务网格等基础设施向智能化演进，实现动态路由、自适应限流与弹性伸缩。
    - 催生AI原生后端架构，更好地支持ML模型服务、特征存储等。
    - AIOps：通过智能监控、异常检测、预测性维护和自动化根因分析，提升系统稳定性和运维效率。
3. **催生新型后端服务与能力**：
    
    - 使得构建AI即服务（AIaaS）平台、高级个性化推荐引擎、复杂NLP接口等新型后端应用成为可能。
    - 强化后端实时数据处理、智能决策与自动化流程的能力。
4. **后端工程师角色与技能转型**：
    
    - 工程师角色从纯粹的“编码者”向AI工具的“使用者、编排者、验证者”转变。
    - 对AI/ML基础、数据工程、MLOps以及提示工程等技能的需求日益增加。
5. **核心挑战与审慎考量**：
    
    - 需关注AI生成代码/设计的质量、安全性、可解释性和可维护性。
    - 警惕过度依赖可能导致的技能退化，并重视数据隐私、算法偏见及伦理问题。
### 为什么选择后端


## k8s
### k8s的功能