# Daily Plan
#todo
- [ ] 
- [ ] 
# Daily Study
## Transformer学习
主要介绍结构：[Transformer模型详解（图解最完整版） - 知乎](https://zhuanlan.zhihu.com/p/338817680)
待看：[Transformer 架构全解析：从 Attention 机制到编码器 - 解码器，一文吃透核心原理 - 知乎](https://zhuanlan.zhihu.com/p/1897386459046051941)
### 每一层的功能
自注意力机制：它的核心功能是让模型在处理序列中的某个元素时，能够动态计算该元素与序列中其他元素的关联程度（即 “注意力权重”），从而聚焦于对当前元素最相关的信息，忽略无关信息。


### 问题
每一层的功能是什么
mask矩阵怎么算出来的
Q、K、V矩阵怎么算出来的
lora微调具体参数设置
学习率
批次大小
优化器

# Daily Problem