# Daily Plan
#todo
- [ ] 
- [ ] 
# Daily Study
## Transformer学习
链接：[Transformer模型详解（图解最完整版） - 知乎](https://zhuanlan.zhihu.com/p/338817680)
### 每一层的功能
自注意力机制：它的核心功能是让模型在处理序列中的某个元素时，能够动态计算该元素与序列中其他元素的关联程度（即 “注意力权重”），从而聚焦于对当前元素最相关的信息，忽略无关信息。


### 问题
每一层的功能是什么
mask矩阵怎么算出来的
Q、K、V矩阵怎么算出来的

# Daily Problem